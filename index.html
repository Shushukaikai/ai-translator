<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ğŸ™ AIè‹±æ±‰è¯­éŸ³ç¿»è¯‘</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-100 p-6">
  <h1 class="text-2xl font-bold mb-4">ğŸ™ AI è‹±æ±‰ç¿»è¯‘ï¼ˆæ”¯æŒ iPadï¼‰</h1>

  <button id="recordBtn" class="bg-blue-600 text-white px-4 py-2 rounded mb-4">
    âºï¸ å¼€å§‹å½•éŸ³
  </button>

  <p><strong>åŸå§‹è¯­éŸ³è¯†åˆ«ï¼š</strong> <span id="speechText" class="text-gray-800">ï¼ˆç­‰å¾…ä¸Šä¼ ï¼‰</span></p>
  <p><strong>ç¿»è¯‘ç»“æœï¼š</strong> <span id="translatedText" class="text-blue-800 font-bold">ï¼ˆç­‰å¾…è¯†åˆ«ï¼‰</span></p>

  <script>
    let mediaRecorder, audioChunks = [];
    const recordBtn = document.getElementById("recordBtn");
    const speechText = document.getElementById("speechText");
    const translatedText = document.getElementById("translatedText");

    recordBtn.onclick = async () => {
      if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
        recordBtn.innerText = "âºï¸ å¼€å§‹å½•éŸ³";
        return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("audio", blob, "recording.webm");

        speechText.innerText = "â³ æ­£åœ¨è¯†åˆ«ä¸­...";
        translatedText.innerText = "ï¼ˆç­‰å¾…ç¿»è¯‘ï¼‰";

        try {
          // 1. è°ƒç”¨æµ‹è¯• Whisper APIï¼ˆæ— éœ€ Keyï¼‰
          const whisperRes = await fetch("https://deepseek-whisper-api.vercel.app/api/whisper", {
            method: "POST",
            body: formData
          });
          const whisperData = await whisperRes.json();
          const originalText = whisperData.text || "(è¯†åˆ«å¤±è´¥)";
          speechText.innerText = originalText;

          // 2. è°ƒç”¨ LibreTranslate ç¿»è¯‘
          const lang = /[\u4e00-\u9fa5]/.test(originalText) ? "en" : "zh";
          const transRes = await fetch("https://libretranslate.de/translate", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              q: originalText,
              source: "auto",
              target: lang,
              format: "text"
            })
          });
          const transData = await transRes.json();
          translatedText.innerText = transData.translatedText || "âš ï¸ ç¿»è¯‘å¤±è´¥";

        } catch (e) {
          speechText.innerText = "âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥";
          translatedText.innerText = "âš ï¸ ç¿»è¯‘å¤±è´¥";
        }
      };

      mediaRecorder.start();
      recordBtn.innerText = "ğŸ›‘ åœæ­¢å½•éŸ³";
    };
  </script>
</body>
</html>
